{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project IV. Scene recognition with bag of words\n",
    "\n",
    "1. Tiny image features and nearest neighbor classifier  \n",
    "2. Bag of word features and nearest neighbor classifier  \n",
    "3. Bag of word features and linear SVM classifier  \n",
    "\n",
    "Your need complete following functions:  \n",
    "    get_tiny_images, build_vocabulary, get_bags_of_words, svm_classify, nearest_neighbor_classify  \n",
    "1. Tiny + KNN (get_tiny_images, nearest_neighbor_classify)  \n",
    "2. BOW + KNN (build_vocabulary, get_bags_of_words, nearest_neighbor_classify)  \n",
    "3. BOW + SVM (build_vocabulary, get_bags_of_words, nearest_neighbor_classify)  \n",
    "\n",
    "For feature extractor and SVM, using sklearn and skimage is acceptable.\n",
    "\n",
    "The starter code is initialized to 'placeholder' just so that the starter code does not crash when run unmodified and you can get a preview of how results are presented.\n",
    "\n",
    "    Interpreting your performance with 100 training examples per category:\n",
    "     accuracy  =   0 -> Something is broken.\n",
    "     accuracy ~= .07 -> Your performance is equal to chance.\n",
    "                        Something is broken or you ran the starter code unchanged.\n",
    "     accuracy ~= .20 -> Rough performance with tiny images and nearest\n",
    "                        neighbor classifier. Performance goes up a few\n",
    "                        percentage points with K-NN instead of 1-NN.\n",
    "     accuracy ~= .20 -> Rough performance with tiny images and linear SVM\n",
    "                        classifier. Although the accuracy is about the same as\n",
    "                        nearest neighbor, the confusion matrix is very different.\n",
    "     accuracy ~= .40 -> Rough performance with bag of word and nearest\n",
    "                        neighbor classifier. Can reach .60 with K-NN and\n",
    "                        different distance metrics.\n",
    "     accuracy ~= .50 -> You've gotten things roughly correct with bag of\n",
    "                        word and a linear SVM classifier.\n",
    "     accuracy >= .70 -> You've also tuned your parameters well. E.g. number\n",
    "                        of clusters, SVM regularization, number of patches\n",
    "                        sampled when building vocabulary, size and step for\n",
    "                        dense features.\n",
    "     accuracy >= .80 -> You've added in spatial information somehow or you've\n",
    "                        added additional, complementary image features. This\n",
    "                        represents state of the art in Lazebnik et al 2006.\n",
    "     accuracy >= .85 -> You've done extremely well. This is the state of the\n",
    "                        art in the 2010 SUN database paper from fusing many\n",
    "                        features. Don't trust this number unless you actually\n",
    "                        measure many random splits.\n",
    "     accuracy >= .90 -> You used modern deep features trained on much larger\n",
    "                        image databases.\n",
    "     accuracy >= .96 -> You can beat a human at this task. This isn't a\n",
    "                        realistic number. Some accuracy calculation is broken\n",
    "                        or your classifier is cheating and seeing the test\n",
    "                        labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: Set up parameters, category list, and image paths.\n",
    "Uncomment various feature and classifier combinations to test them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from helpers import get_image_paths\n",
    "from student import get_tiny_images, build_vocabulary, get_bags_of_words, \\\n",
    "    svm_classify, nearest_neighbor_classify\n",
    "from create_results_webpage import create_results_webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE = 'tiny image'\n",
    "# FEATURE = 'bag of words'\n",
    "FEATURE = 'placeholder'\n",
    "\n",
    "# CLASSIFIER = 'nearest neighbor'\n",
    "#CLASSIFIER = 'support vector machine'\n",
    "CLASSIFIER = 'placeholder'\n",
    "\n",
    "# This is the path the script will look at to load images from.\n",
    "data_path = '../data/'\n",
    "\n",
    "# This is the list of categories / directories to use. The categories are\n",
    "# somewhat sorted by similarity so that the confusion matrix looks more\n",
    "# structured (indoor and then urban and then rural).\n",
    "categories = ['Kitchen', 'Store', 'Bedroom', 'LivingRoom', 'Office',\n",
    "       'Industrial', 'Suburb', 'InsideCity', 'TallBuilding', 'Street',\n",
    "       'Highway', 'OpenCountry', 'Coast', 'Mountain', 'Forest']\n",
    "\n",
    "# This list of shortened category names is used later for visualization.\n",
    "abbr_categories = ['Kit', 'Sto', 'Bed', 'Liv', 'Off', 'Ind', 'Sub',\n",
    "    'Cty', 'Bld', 'St', 'HW', 'OC', 'Cst', 'Mnt', 'For']\n",
    "\n",
    "# Number of training examples per category to use. Max is 100. For\n",
    "# simplicity, we assume this is the number of test cases per category as\n",
    "# well.\n",
    "num_train_per_cat = 100\n",
    "\n",
    "# This function returns string arrays containing the file path for each train\n",
    "# and test image, as well as string arrays with the label of each train and\n",
    "# test image. By default all four of these arrays will be 1500x1 where each\n",
    "# entry is a string.\n",
    "print('Getting paths and labels for all train and test data.')\n",
    "train_image_paths, test_image_paths, train_labels, test_labels = \\\n",
    "    get_image_paths(data_path, categories, num_train_per_cat)\n",
    "#   train_image_paths  1500x1   list\n",
    "#   test_image_paths   1500x1   list\n",
    "#   train_labels       1500x1   list\n",
    "#   test_labels        1500x1   list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Represent each image with the appropriate feature\n",
    "Each function to construct features should return an N x d matrix, where\n",
    "N is the number of paths passed to the function and d is the\n",
    "dimensionality of each image representation. See the starter code for\n",
    "each function for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "print('Using %s representation for images.' % FEATURE)\n",
    "\n",
    "if FEATURE.lower() == 'tiny image':\n",
    "    print('Loading tiny images...')\n",
    "    # YOU CODE get_tiny_images (see student.py)\n",
    "    train_image_feats = get_tiny_images(train_image_paths)\n",
    "    test_image_feats  = get_tiny_images(test_image_paths)\n",
    "    print('Tiny images loaded.')\n",
    "\n",
    "elif FEATURE.lower() == 'bag of words':\n",
    "    # Because building the vocabulary takes a long time, we save the generated\n",
    "    # vocab to a file and re-load it each time to make testing faster. If\n",
    "    # you need to re-generate the vocab (for example if you change its size\n",
    "    # or the length of your feature vectors), simply delete the vocab.npy\n",
    "    # file and re-run main.py\n",
    "    \n",
    "    if not os.path.isfile('vocab.npy'):\n",
    "        print('No existing visual word vocabulary found. Computing one from training images.')\n",
    "        #Larger values will work better (to a point), but are slower to compute\n",
    "        vocab_size = 200\n",
    "\n",
    "        # YOU CODE build_vocabulary (see student.py)\n",
    "        vocab = build_vocabulary(train_image_paths, vocab_size)\n",
    "        np.save('vocab.npy', vocab)\n",
    "\n",
    "    # YOU CODE get_bags_of_words.m (see student.py)\n",
    "    train_image_feats = get_bags_of_words(train_image_paths)\n",
    "    \n",
    "    # You may want to write out train_image_features here as a *.npy and\n",
    "    # load it up later if you want to just test your classifiers without\n",
    "    # re-computing features\n",
    "    test_image_feats  = get_bags_of_words(test_image_paths)\n",
    "    # Same goes here for test image features.\n",
    "\n",
    "elif FEATURE.lower() == 'placeholder':\n",
    "    train_image_feats = []\n",
    "    test_image_feats = []\n",
    "else:\n",
    "    raise ValueError('Unknown feature type!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Classify each test image by training and using the appropriate classifier\n",
    "Each function to classify test features will return an N x 1 string array,\n",
    "where N is the number of test cases and each entry is a string indicating\n",
    "the predicted category for each test image. Each entry in\n",
    "'predicted_categories' must be one of the 15 strings in 'categories',\n",
    "'train_labels', and 'test_labels'. See the starter code for each function\n",
    "for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Using %s classifier to predict test set categories.' % CLASSIFIER)\n",
    "\n",
    "if CLASSIFIER.lower() == 'nearest neighbor':\n",
    "    # YOU CODE nearest_neighbor_classify (see student.py)\n",
    "    predicted_categories = nearest_neighbor_classify(train_image_feats, train_labels, test_image_feats)\n",
    "\n",
    "elif CLASSIFIER.lower() == 'support vector machine':\n",
    "    # YOU CODE svm_classify (see student.py)\n",
    "    predicted_categories = svm_classify(train_image_feats, train_labels, test_image_feats)\n",
    "\n",
    "elif CLASSIFIER.lower() == 'placeholder':\n",
    "    #The placeholder classifier simply predicts a random category for every test case\n",
    "    random_permutation = np.random.permutation(len(test_labels))\n",
    "    predicted_categories = [test_labels[i] for i in random_permutation]\n",
    "\n",
    "else:\n",
    "    raise ValueError('Unknown classifier type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Build a confusion matrix and score the recognition system\n",
    "You do not need to code anything in this section.\n",
    "If we wanted to evaluate our recognition method properly we would train\n",
    "and test on many random splits of the data. You are not required to do so\n",
    "for this project.\n",
    "This function will recreate results_webpage/index.html and various image\n",
    "thumbnails each time it is called. View the webpage to help interpret\n",
    "your classifier performance. Where is it making mistakes? Are the\n",
    "confusions reasonable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_results_webpage( train_image_paths, \\\n",
    "                            test_image_paths, \\\n",
    "                            train_labels, \\\n",
    "                            test_labels, \\\n",
    "                            categories, \\\n",
    "                            abbr_categories, \\\n",
    "                            predicted_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('pytorch': conda)",
   "metadata": {
    "interpreter": {
     "hash": "eb031bbce033fa812dcec88de62f5abea6a352f76cdf43a5d1f21e2ea96289b4"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
